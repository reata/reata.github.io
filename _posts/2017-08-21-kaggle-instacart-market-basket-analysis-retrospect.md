---
title: "Kaggle Instacart复购预测竞赛回顾"
excerpt: "客户下次会购买什么"
header:
  overlay_image: assets/images/instacart.png
  overlay_filter: 0.4
  caption: "图片引用自https://kaggle2.blob.core.windows.net/competitions/kaggle/6644/logos/header.png"
categories:
  - kaggle
  - classification
tags:
  - machine learning
  - e-commerce re-order
author: "胡俊伟"
date: "21 August 2017"
---

Instacart是一家食品类垂直电商，在Kaggle上举办的这场比赛中，参赛人员需要利用其公开的交易数据建立机器学习模型，预测用户会再度购买哪些商品。

知道用户可能会购买哪些商品，有什么样的用处呢？最直接的，网站可以给用户针对性地发优惠券促销，而更远景的目标，结合一些其它数据，或许可以做销量预测和库存优化，节约仓储、采购成本。

### 已有数据集

比赛使用的数据仅包含交易数据，不包含浏览数据。主要由以下几张表构成：

1. 订单表 orders（订单ID，用户ID，所属数据集，该用户的订单序号，订单下单在星期几，订单下单所在小时，距离上一次下单过去的天数）：数据粒度为一个订单事实。其中，所属数据集包含三类：a) 先验集：所有用户在历史一段时间内产生的所有订单；b) 训练集：从所有用户中抽出一部分训练用户，在考察周期内产生的所有订单；c) 测试集：除去训练用户外剩下的用户，在考察周期内产生的所有订单。先验集中，每个用户可能包含多个订单。而对于训练集和测试集，两者的用户无交集外，每个用户在各自集合内也只会有一个订单。

2. 商品表 products（商品ID，商品名称，通道ID，分类ID）：数据粒度为一件商品。

3. 通道表 aisles（通道ID，通道名称）：数据粒度为一个通道。这里的通道，就是超市里的通道，每一个通道两侧的商品，通常是一个类别的。

4. 分类表 departments（分类ID，分类名称）：数据粒度为一个分类。是比通道更大的分类概念，但二者相互没有确定的包含关系。

5. 先验集订单商品表 order_products_prior（订单ID，商品ID，加入购物车的次序，是否复购）：注意先验集包含所有的用户，这里的数据粒度是历史一段时期内，所有用户购买的所有商品记录。

6. 训练集订单商品表 order_products_train（订单ID，商品ID，加入购物车次序，是否复购）：这里是训练集用户，在考察期内，购买的所有商品记录。上面提过，这个数据集里的每个用户，只会有一个订单，其中包含若干个商品，可能包含也可能不包含复购的商品。

如果不使用NLP的方法对名称类字段进行处理的话，商品名称、通道名称、分类名称这几个字段是没有用的。由于在实际项目中，也没有进行相关处理，后面这几个字段将略过不谈。

最终产出的数据，是订单表的测试集中，每个订单所包含的复购商品，也即仅包含复购的测试集订单商品表。由于上面提到了，训练集和测试集实际上是按照用户划分的，所以最终提交的数据，也是测试用户在考察期间内，复购的所有商品。

### 问题的评价标准

按照每个用户实际复购的商品，和预测复购的商品，针对单个用户计算F1得分，最终再按用户人均的F1得分。

复购预测是一个典型的非均衡分类问题，绝大多数的商品都会落入TN的范围内——一件商品，算法预测不复购、用户实际也没有复购，所以准确率Accuracy是一个不好的指标，预测用户不复购任何商品，这个分类问题就可以得到很高的准确率。

与此同时，精准率Precision和召回率Recall也都不足以描述问题的关键。

片面考虑精准率，算法会趋于谨慎，只预测非常有把握实际会复购的，从而漏掉一部分实际复购的；覆盖面不够广，促销的力度可能不够。

片面考虑召回率，算法会趋于冒险，尽可能多地把实际复购的商品都挑选出来，从而预测了一部分实际上用户没有复购的；覆盖面过于广，造成促销活动的浪费。

F1 = 2 / (1/Precision + 1/Recall) = 2TP / (2TP + FP + FN)

注意到，在F1的计算过程中，TN是不纳入计算的。这也符合问题的初衷。

### 机器学习表述

将业务问题转化为一个机器学习问题的过程常常是项目成败的关键。从业务方提过来的问题，更贴近于业务现实，比如“最近公司的优惠券发得太漫无目的了，成本大幅上升，为了更高效地发放优惠券，我们希望能预知用户可能购买的商品”。而后续需要将问题进行机器学习的表述。

汇总出可以取得到的相关数据（使用交易数据，浏览数据很重要但可能无法获得），梳理出问题的评价标准（使用F1，而不是Accuracy）是问题的机器学习表述中极为关键的步骤。数据决定了后续算法的潜力如何，而评价标准则决定了算法潜力兑现后，模型多大程度上解决了业务问题。

而剩下的关键问题是，机器学习建模。我们面临的是哪一类机器学习问题？模型的粒度，也就是说，一条训练样本代表着什么？

在梳理问题评价标准的同时，我们已经发现，这是一个分类问题。给定一个用户，一件商品，算法需要预测出，用户是否会复购这件商品，因而模型的粒度是用户-商品。而复购，意味着用户曾经购买过这件商品才可能形成复购，不需要将所有用户和所有商品做笛卡尔积，挑选出各位用户及其曾经购买过的所有商品组合即可。

注意到，在给定的数据集中，订单的粒度是一个订单，对应着一个用户的一次下单行为，订单商品的粒度是一个订单商品，对应着一个用户的一次商品购买，用户-商品组合可能出现多次。而我们的模型要求，每个用户-商品只允许出现一次，所以各类特征，不能简单从原始表中直接拿来用，而是需要根据用户-商品的粒度做一些聚合操作。

### 特征工程之维度建模

### 无复购的处理

### 算法的优化目标 vs 问题的优化目标

### 参考阅读
